# https://cwiki.apache.org/confluence/display/hive/configuration+properties

# JDBC connect string for a JDBC metastore.
# javax.jdo.option.ConnectionURL
HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://postgres:5432/hivemetastore

# Driver class name for a JDBC metastore.
# javax.jdo.option.ConnectionDriverName
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver

# Username to use against metastore database
# javax.jdo.option.ConnectionUserName
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive

# Password to use against metastore database.
# javax.jdo.option.ConnectionPassword
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive

# Creates necessary schema on a startup if one does not exist. Reset this to false, after creating it once.
# datanucleus.schema.autoCreateAll is disabled if hive.metastore.schema.verification is true.
# datanucleus.schema.autoCreateAll
HIVE_SITE_CONF_datanucleus_schema_autoCreateAll=false

# Controls whether to connect to remote metastore server.
# If hive.metastore.uris is set then remote mode is assumed otherwise local.
# hive.metastore.uris
HIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083

# Enforce metastore schema version consistency.
# True:  Verify that version information stored in metastore matches with one from Hive jars. 
#        Also disable automatic schema migration attempt (see datanucleus.autoCreateSchema and datanucleus.schema.autoCreateAll). 
#        Users are required to manually migrate schema after Hive upgrade which ensures proper metastore schema migration.
# False: Warn if the version information stored in metastore doesn't match with one from Hive jars.
# datanucleus.schema.autoCreateAll is disabled if hive.metastore.schema.verification is true.
# hive.metastore.schema.verification
HIVE_SITE_CONF_hive_metastore_schema_verification=false



# https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark
# https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started

# Chooses execution engine. Options are: mr (Map Reduce, default), tez (Tez execution, for Hadoop 2 only), or spark (Spark execution, for Hive 1.1.0 onward).
# hive.execution.engine
HIVE_SITE_CONF_hive_execution_engine=spark

# Whether Hive supports concurrency or not. A ZooKeeper instance must be up and running for the default Hive lock manager to support read-write locks.
# Set to true to support INSERT ... VALUES, UPDATE, and DELETE transactions (Hive 0.14.0 and later). 
# For a complete list of parameters required for turning on Hive transactions, see hive.txn.manager.
# hive.support.concurrency
HIVE_SITE_CONF_hive_support_concurrency=false


# Location of default database for the warehouse.
# hive.metastore.warehouse.dir
# HIVE_SITE_CONF_hive_metastore_warehouse_dir=s3a://hive/warehouse
HIVE_SITE_CONF_hive_metastore_warehouse_dir=/usr/hive/warehouse

# Setting this property to true will have HiveServer2 execute Hive operations as the user making the calls to it.
# hive.server2.enable.doAs
HIVE_SITE_CONF_hive_server2_enable_doAs=false

